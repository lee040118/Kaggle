{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/USER/kaggle/building/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06004A01002010000</td>\n",
       "      <td>10_콘크리트외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61673A01001310000</td>\n",
       "      <td>10_콘크리트외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54554A01011750001</td>\n",
       "      <td>20_조적외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50653A09001530000</td>\n",
       "      <td>10_콘크리트외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01743001003600009</td>\n",
       "      <td>10_콘크리트외벽</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID     Target\n",
       "0  06004A01002010000  10_콘크리트외벽\n",
       "1  61673A01001310000  10_콘크리트외벽\n",
       "2  54554A01011750001    20_조적외벽\n",
       "3  50653A09001530000  10_콘크리트외벽\n",
       "4  01743001003600009  10_콘크리트외벽"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(DATASET_PATH, 'train', 'train.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>63034901002670000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>47523002007170006</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>54078A0620012100000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>17794A04000000000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>29160901006020000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>29160901006850010</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>10863905000350036</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>28378901016970000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>34068001006390008</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>28132A05001010030</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>63594A01000400000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>52061A12000190000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>12189A02000690000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3614</th>\n",
       "      <td>50867A02001450001</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>38577A35000220000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>49393901005130002</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>11164A01002790000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>37838A04000490000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6942</th>\n",
       "      <td>02056901002390001</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>18581A11000350000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>01762A03000170000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>52606A06000010010</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10746</th>\n",
       "      <td>17118A06000510018</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12710</th>\n",
       "      <td>15644A05000680101</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12923</th>\n",
       "      <td>11679A03000100000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13412</th>\n",
       "      <td>15644A05000680087</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13901</th>\n",
       "      <td>17997A02000870000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15671</th>\n",
       "      <td>10046A0420014200001</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16404</th>\n",
       "      <td>50316A10000110000</td>\n",
       "      <td>50_기타외벽</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID   Target\n",
       "37       63034901002670000  50_기타외벽\n",
       "606      47523002007170006  50_기타외벽\n",
       "684    54078A0620012100000  50_기타외벽\n",
       "1388     17794A04000000000  50_기타외벽\n",
       "1821     29160901006020000  50_기타외벽\n",
       "1822     29160901006850010  50_기타외벽\n",
       "1823     10863905000350036  50_기타외벽\n",
       "1824     28378901016970000  50_기타외벽\n",
       "1825     34068001006390008  50_기타외벽\n",
       "2254     28132A05001010030  50_기타외벽\n",
       "2499     63594A01000400000  50_기타외벽\n",
       "2566     52061A12000190000  50_기타외벽\n",
       "3283     12189A02000690000  50_기타외벽\n",
       "3614     50867A02001450001  50_기타외벽\n",
       "4466     38577A35000220000  50_기타외벽\n",
       "5627     49393901005130002  50_기타외벽\n",
       "5695     11164A01002790000  50_기타외벽\n",
       "6475     37838A04000490000  50_기타외벽\n",
       "6942     02056901002390001  50_기타외벽\n",
       "8372     18581A11000350000  50_기타외벽\n",
       "8579     01762A03000170000  50_기타외벽\n",
       "10400    52606A06000010010  50_기타외벽\n",
       "10746    17118A06000510018  50_기타외벽\n",
       "12710    15644A05000680101  50_기타외벽\n",
       "12923    11679A03000100000  50_기타외벽\n",
       "13412    15644A05000680087  50_기타외벽\n",
       "13901    17997A02000870000  50_기타외벽\n",
       "15671  10046A0420014200001  50_기타외벽\n",
       "16404    50316A10000110000  50_기타외벽"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data.Target == '50_기타외벽')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, mode):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        if mode == 'val':\n",
    "            self.mode = 'train'\n",
    "        else:\n",
    "            self.mode = mode\n",
    "        self.data_dir = os.path.join(root, self.mode, 'images')\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.data = pd.read_csv(os.path.join(root, self.mode, f'{self.mode}.csv'))\n",
    "            self.data = self.data[:int(TRAIN_RATIO*len(self.data))]\n",
    "        elif mode == 'val':\n",
    "            self.data = pd.read_csv(os.path.join(root, self.mode, f'{self.mode}.csv'))\n",
    "            self.data = self.data[int(TRAIN_RATIO*len(self.data)):].reset_index()\n",
    "        else:\n",
    "            self.data = pd.read_csv(os.path.join(root, 'sample_submission.csv'))\n",
    "        \n",
    "        # Target 카테고리 -> 정수\n",
    "        self.data = self.data.replace(['10_콘크리트외벽', '20_조적외벽', '30_판넬외벽', '40_유리외벽', '50_기타외벽'], [0, 1, 2, 3, 4])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        b_id = self.data['ID'][idx]\n",
    "\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(self.data_dir, b_id + '.png'))\n",
    "            img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "            img = cv2.normalize(img, img, 0, 255, cv2.NORM_MINMAX)\n",
    "        except:\n",
    "            img = np.zeros((256, 256, 3))\n",
    "\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "        img = img.permute(2, 0, 1)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            target = []\n",
    "        else:\n",
    "            target = self.data['Target'][idx]\n",
    "            target = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        return (b_id+'.png', img, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def custom_evaluate(label, prediction):\n",
    "    label = list(map(int, label))\n",
    "    prediction = list(map(int, prediction))\n",
    "    return f1_score(label, prediction, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EfficientNet-PyTorch\n",
    "[github](https://github.com/lukemelas/EfficientNet-PyTorch)\n",
    "\n",
    "![](https://raw.githubusercontent.com/tensorflow/tpu/master/models/official/efficientnet/g3doc/params.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.channel = 1792 #b1: 1280, b4: 1792\n",
    "        self.h = 8\n",
    "        self.w = 8\n",
    "\n",
    "        # 1 epoch train time aprox. 25 min\n",
    "        self.en = EfficientNet.from_pretrained('efficientnet-b4').to(device)\n",
    "        self.avp = nn.AvgPool2d(self.h, stride=1, padding=0)\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=self.channel, out_features=5, bias=True),\n",
    "            nn.Softmax(dim=1)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.en.extract_features(x)\n",
    "        x = self.avp(features)\n",
    "        x = x.squeeze()\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "    else:\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "    model = CNN().to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "\n",
    "    # DataLoader\n",
    "    training_params = {'batch_size': batch_size,\n",
    "                    'shuffle': True,\n",
    "                    'drop_last': True,\n",
    "                    'collate_fn': None,\n",
    "                    'num_workers': 0}\n",
    "    validating_params = {'batch_size': batch_size,\n",
    "                    'shuffle': True,\n",
    "                    'drop_last': True,\n",
    "                    'collate_fn': None,\n",
    "                    'num_workers': 0}\n",
    "\n",
    "    training_set = CustomDataset(root=DATASET_PATH, mode='train')\n",
    "    training_generator = DataLoader(training_set, **training_params)\n",
    "    validating_set = CustomDataset(root=DATASET_PATH, mode='val')\n",
    "    validating_generator = DataLoader(validating_set, **validating_params)\n",
    "\n",
    "    # Print trainable number of parameters\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"num of parameter : \", total_params)\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"num of trainable parameter :\", trainable_params)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "\n",
    "    # Train Model\n",
    "    val_acc_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = datetime.datetime.now()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_score = 0.0\n",
    "        for iter, (_, imgs, target) in enumerate(training_generator):\n",
    "            try:\n",
    "                imgs, target = imgs.to(device), target.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(imgs)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                output = torch.argmax(output, dim=1)\n",
    "                running_score += custom_evaluate(target, output)\n",
    "\n",
    "                if iter % 10 == 9:\n",
    "                    print(f'Train Epoch: {epoch} [ {iter * len(imgs)}/{len(training_generator.dataset)} ({100. * iter / len(training_generator)}%)]\\tLoss: {loss.item()}')\n",
    "\n",
    "                if iter % 20 == 19:\n",
    "                    print(f'[{epoch}, {iter}] loss: {running_loss / 20}, f1 score: {running_score / 20}')\n",
    "                    running_loss = 0.0\n",
    "                    running_score = 0.0\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Error:', e)\n",
    "                continue\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        print(f'\\nEpoch: {epoch}, loss: {loss.item()}')\n",
    "        print(f'(epoch)time: {datetime.datetime.now() - epoch_start}')\n",
    "\n",
    "        if epoch % save_epochs == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(log_dir,f'epoch_{epoch}.pth'))\n",
    "            print('Model Saved')\n",
    "\n",
    "        if epoch % val_epochs == 0:\n",
    "            val_start = datetime.datetime.now()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_targets = []\n",
    "                val_outputs = []\n",
    "                for iter, (_, imgs, target) in enumerate(validating_generator):\n",
    "                    try:\n",
    "                        imgs = imgs.to(device)\n",
    "                        target = target.to(device)\n",
    "\n",
    "                        output = model(imgs)\n",
    "                        output = torch.argmax(output, dim=1)\n",
    "\n",
    "                        val_targets.append(target)\n",
    "                        val_outputs.append(output)\n",
    "\n",
    "                        if iter % 500 == 0:\n",
    "                            print(f'epoch: {epoch}, batch val: {custom_evaluate(target, output)}')\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f'Validation Error: {e}')\n",
    "                        continue\n",
    "\n",
    "            val_targets = torch.cat(val_targets, dim=0)\n",
    "            val_outputs = torch.cat(val_outputs, dim=0)\n",
    "            val_score = custom_evaluate(val_targets, val_outputs)\n",
    "            print(f'(val)time: {datetime.datetime.now() - val_start}')\n",
    "            print(f'Validation Score: {val_score}\\n===============\\n\\n')\n",
    "            val_acc_history.append([epoch, val_score])\n",
    "\n",
    "            model.train()\n",
    "\n",
    "    # Print Validation Scores\n",
    "    for epoch, score in val_acc_history:\n",
    "        print(f'Epoch: {epoch}, Score: {score}')\n",
    "\n",
    "    # save final result\n",
    "    torch.save(model.state_dict(), os.path.join(log_dir,'/last.pth'))\n",
    "    print('\\n\\nModel Saved, Finishing training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "\n",
    "    # weight = weight\n",
    "    batch_size = 128\n",
    "    prediction = prediction_file\n",
    "\n",
    "    # Load Model\n",
    "    model = CNN().to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(log_dir,f'{weight}')))\n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    # DataLoader\n",
    "    testing_params = {'batch_size': batch_size,\n",
    "                    'shuffle': False,\n",
    "                    'drop_last': False,\n",
    "                    'collate_fn': None,\n",
    "                    'num_workers': 0}\n",
    "\n",
    "    testing_set = CustomDataset(root=DATASET_PATH, mode='test')\n",
    "    testing_generator = DataLoader(testing_set, **testing_params)\n",
    "    print('test dataset ready---')\n",
    "\n",
    "    # Test\n",
    "    test_bids = []\n",
    "    test_preds = []\n",
    "    for iter, (b_ids, imgs, _) in enumerate(testing_generator):\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                imgs = imgs.to(device)\n",
    "                output = model(imgs)\n",
    "                output = torch.argmax(output, dim=1)\n",
    "                test_bids.extend(b_ids)\n",
    "                test_preds.append(output)\n",
    "\n",
    "                if iter % 100 == 0:\n",
    "                    print(f'iter: {iter}')\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Testing Error:', e)\n",
    "                sys.exit()\n",
    "\n",
    "    test_preds = torch.cat(test_preds, dim=0)\n",
    "    test_preds = test_preds.cpu().data.numpy()\n",
    "    save_result(test_bids, test_preds, path=prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_result(names, y_pred, path='prediction2.csv'):\n",
    "    try:\n",
    "        int2code = {0: '10_콘크리트외벽', \n",
    "                    1: '20_조적외벽',\n",
    "                    2: '30_판넬외벽',\n",
    "                    3: '40_유리외벽',\n",
    "                    4: '50_기타외벽'}\n",
    "        \n",
    "        y_pred = list(map(lambda x : int2code[x], y_pred))\n",
    "        with open(os.path.join(log_dir,path), 'w', encoding='utf-8', newline='') as f:\n",
    "            f.write('ID,Target\\n')\n",
    "            for i, pred in enumerate(y_pred):\n",
    "                filename = names[i].split('.')[0]\n",
    "                f.write(f'{str(filename)},{str(pred)}\\n')\n",
    "        print(f'Saved result {path}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Fail to save {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for `libpng error: Read Error`\n",
    "# !pip install update libpng-bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 2e-4\n",
    "batch_size = 32\n",
    "val_epochs = 1\n",
    "save_epochs = 1\n",
    "weight = 'last.pth'\n",
    "prediction_file = 'prediction.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ec352e0640416c888240cb640ddc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/74.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "------------------------------------------------------------\n",
      "num of parameter :  19350581\n",
      "num of trainable parameter : 19350581\n",
      "------------------------------------------------------------\n",
      "Train Epoch: 0 [ 288/16586 (1.7374517374517375%)]\tLoss: 1.5137020349502563\n",
      "Train Epoch: 0 [ 608/16586 (3.667953667953668%)]\tLoss: 1.374488353729248\n",
      "[0, 19] loss: 1.48594172000885, f1 score: 0.36863464653406786\n",
      "Train Epoch: 0 [ 928/16586 (5.598455598455598%)]\tLoss: 1.1622593402862549\n",
      "Train Epoch: 0 [ 1248/16586 (7.528957528957529%)]\tLoss: 1.1642582416534424\n",
      "[0, 39] loss: 1.216974174976349, f1 score: 0.5245664150880626\n",
      "Train Epoch: 0 [ 1568/16586 (9.45945945945946%)]\tLoss: 1.1036995649337769\n",
      "Train Epoch: 0 [ 1888/16586 (11.38996138996139%)]\tLoss: 1.214789867401123\n",
      "[0, 59] loss: 1.1464894950389861, f1 score: 0.533198850901746\n",
      "Train Epoch: 0 [ 2208/16586 (13.32046332046332%)]\tLoss: 1.1277358531951904\n",
      "Train Epoch: 0 [ 2528/16586 (15.250965250965251%)]\tLoss: 1.050053596496582\n",
      "[0, 79] loss: 1.1115795850753785, f1 score: 0.5405029321443748\n",
      "Train Epoch: 0 [ 2848/16586 (17.18146718146718%)]\tLoss: 1.0760306119918823\n",
      "Train Epoch: 0 [ 3168/16586 (19.111969111969113%)]\tLoss: 1.0836654901504517\n",
      "[0, 99] loss: 1.1189540088176728, f1 score: 0.5052370194547412\n",
      "Train Epoch: 0 [ 3488/16586 (21.042471042471043%)]\tLoss: 1.159830093383789\n",
      "Train Epoch: 0 [ 3808/16586 (22.972972972972972%)]\tLoss: 1.1512014865875244\n",
      "[0, 119] loss: 1.1329781413078308, f1 score: 0.4999016075172091\n",
      "Train Epoch: 0 [ 4128/16586 (24.903474903474905%)]\tLoss: 1.1834336519241333\n",
      "Train Epoch: 0 [ 4448/16586 (26.833976833976834%)]\tLoss: 1.1683510541915894\n",
      "[0, 139] loss: 1.1246787488460541, f1 score: 0.4917099749582217\n",
      "Train Epoch: 0 [ 4768/16586 (28.764478764478763%)]\tLoss: 1.1064963340759277\n",
      "Train Epoch: 0 [ 5088/16586 (30.694980694980696%)]\tLoss: 1.1542339324951172\n",
      "[0, 159] loss: 1.1115243971347808, f1 score: 0.5400384198454017\n",
      "Train Epoch: 0 [ 5408/16586 (32.625482625482626%)]\tLoss: 1.1471693515777588\n",
      "Train Epoch: 0 [ 5728/16586 (34.55598455598456%)]\tLoss: 1.180445671081543\n",
      "[0, 179] loss: 1.1213088631629944, f1 score: 0.4989282802696689\n",
      "Train Epoch: 0 [ 6048/16586 (36.486486486486484%)]\tLoss: 1.1663269996643066\n",
      "Train Epoch: 0 [ 6368/16586 (38.41698841698842%)]\tLoss: 1.086958646774292\n",
      "[0, 199] loss: 1.1114820003509522, f1 score: 0.5550213159091714\n",
      "Train Epoch: 0 [ 6688/16586 (40.34749034749035%)]\tLoss: 1.0615967512130737\n",
      "Train Epoch: 0 [ 7008/16586 (42.277992277992276%)]\tLoss: 0.9979831576347351\n",
      "[0, 219] loss: 1.1081558108329772, f1 score: 0.5797192585968121\n",
      "Train Epoch: 0 [ 7328/16586 (44.20849420849421%)]\tLoss: 1.1681663990020752\n",
      "Train Epoch: 0 [ 7648/16586 (46.13899613899614%)]\tLoss: 1.2407668828964233\n",
      "[0, 239] loss: 1.1210889875888825, f1 score: 0.5326812670496996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [ 7968/16586 (48.06949806949807%)]\tLoss: 1.0624324083328247\n",
      "Train Epoch: 0 [ 8288/16586 (50.0%)]\tLoss: 1.1080490350723267\n",
      "[0, 259] loss: 1.1017858296632768, f1 score: 0.5855970724329135\n",
      "Train Epoch: 0 [ 8608/16586 (51.93050193050193%)]\tLoss: 1.1267601251602173\n",
      "Train Epoch: 0 [ 8928/16586 (53.86100386100386%)]\tLoss: 1.1509631872177124\n",
      "[0, 279] loss: 1.1062034010887145, f1 score: 0.562809927491803\n",
      "Train Epoch: 0 [ 9248/16586 (55.79150579150579%)]\tLoss: 1.0150549411773682\n",
      "Train Epoch: 0 [ 9568/16586 (57.722007722007724%)]\tLoss: 1.0645555257797241\n",
      "[0, 299] loss: 1.102121502161026, f1 score: 0.55230122576442\n",
      "Train Epoch: 0 [ 9888/16586 (59.65250965250965%)]\tLoss: 1.1017160415649414\n",
      "Train Epoch: 0 [ 10208/16586 (61.58301158301158%)]\tLoss: 1.0900208950042725\n",
      "[0, 319] loss: 1.1259791553020477, f1 score: 0.5331702487783552\n",
      "Train Epoch: 0 [ 10528/16586 (63.513513513513516%)]\tLoss: 1.1247715950012207\n",
      "Train Epoch: 0 [ 10848/16586 (65.44401544401545%)]\tLoss: 1.0774879455566406\n",
      "[0, 339] loss: 1.1103944510221482, f1 score: 0.552795279090593\n",
      "Train Epoch: 0 [ 11168/16586 (67.37451737451738%)]\tLoss: 1.215910792350769\n",
      "Train Epoch: 0 [ 11488/16586 (69.3050193050193%)]\tLoss: 1.12247896194458\n",
      "[0, 359] loss: 1.112653422355652, f1 score: 0.5402414922417889\n",
      "Train Epoch: 0 [ 11808/16586 (71.23552123552123%)]\tLoss: 1.041663646697998\n",
      "Train Epoch: 0 [ 12128/16586 (73.16602316602317%)]\tLoss: 1.0067752599716187\n",
      "[0, 379] loss: 1.0995366156101227, f1 score: 0.5495826459060826\n",
      "Train Epoch: 0 [ 12448/16586 (75.0965250965251%)]\tLoss: 1.1764490604400635\n",
      "Train Epoch: 0 [ 12768/16586 (77.02702702702703%)]\tLoss: 1.1002191305160522\n",
      "[0, 399] loss: 1.1105663001537323, f1 score: 0.5402308931697657\n",
      "Train Epoch: 0 [ 13088/16586 (78.95752895752896%)]\tLoss: 1.2074391841888428\n",
      "Train Epoch: 0 [ 13408/16586 (80.88803088803088%)]\tLoss: 1.2746115922927856\n",
      "[0, 419] loss: 1.1258786201477051, f1 score: 0.5392247119971221\n",
      "Train Epoch: 0 [ 13728/16586 (82.81853281853282%)]\tLoss: 1.127819538116455\n",
      "Train Epoch: 0 [ 14048/16586 (84.74903474903475%)]\tLoss: 1.1240406036376953\n",
      "[0, 439] loss: 1.1097978353500366, f1 score: 0.5541719073269896\n",
      "Train Epoch: 0 [ 14368/16586 (86.67953667953668%)]\tLoss: 1.0671992301940918\n",
      "Train Epoch: 0 [ 14688/16586 (88.61003861003861%)]\tLoss: 0.9869802594184875\n",
      "[0, 459] loss: 1.0884090453386306, f1 score: 0.5270455029227208\n",
      "Train Epoch: 0 [ 15008/16586 (90.54054054054055%)]\tLoss: 1.0895596742630005\n",
      "Train Epoch: 0 [ 15328/16586 (92.47104247104247%)]\tLoss: 1.0219086408615112\n",
      "[0, 479] loss: 1.1252968311309814, f1 score: 0.5627010357997793\n",
      "Train Epoch: 0 [ 15648/16586 (94.4015444015444%)]\tLoss: 1.1708474159240723\n",
      "Train Epoch: 0 [ 15968/16586 (96.33204633204633%)]\tLoss: 1.0593675374984741\n",
      "[0, 499] loss: 1.09323570728302, f1 score: 0.5432240068963614\n",
      "Train Epoch: 0 [ 16288/16586 (98.26254826254826%)]\tLoss: 0.9899619221687317\n",
      "\n",
      "Epoch: 0, loss: 1.1274092197418213\n",
      "(epoch)time: 0:57:20.701678\n",
      "Model Saved\n",
      "epoch: 0, batch val: 0.7948717948717949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val)time: 0:05:45.684353\n",
      "Validation Score: 0.5135233857136235\n",
      "===============\n",
      "\n",
      "\n",
      "Train Epoch: 1 [ 288/16586 (1.7374517374517375%)]\tLoss: 1.059373378753662\n",
      "Train Epoch: 1 [ 608/16586 (3.667953667953668%)]\tLoss: 1.143170714378357\n",
      "[1, 19] loss: 1.1016238451004028, f1 score: 0.5616446016731171\n",
      "Train Epoch: 1 [ 928/16586 (5.598455598455598%)]\tLoss: 1.0004510879516602\n",
      "Train Epoch: 1 [ 1248/16586 (7.528957528957529%)]\tLoss: 1.0338101387023926\n",
      "[1, 39] loss: 1.0700003534555436, f1 score: 0.6080560770669479\n",
      "Train Epoch: 1 [ 1568/16586 (9.45945945945946%)]\tLoss: 1.1089612245559692\n",
      "Train Epoch: 1 [ 1888/16586 (11.38996138996139%)]\tLoss: 1.0928139686584473\n",
      "[1, 59] loss: 1.0744295477867127, f1 score: 0.5445323035801509\n",
      "Train Epoch: 1 [ 2208/16586 (13.32046332046332%)]\tLoss: 1.1165701150894165\n",
      "Train Epoch: 1 [ 2528/16586 (15.250965250965251%)]\tLoss: 1.0618963241577148\n",
      "[1, 79] loss: 1.1011041402816772, f1 score: 0.5336331259514775\n",
      "Train Epoch: 1 [ 2848/16586 (17.18146718146718%)]\tLoss: 1.1855409145355225\n",
      "Train Epoch: 1 [ 3168/16586 (19.111969111969113%)]\tLoss: 1.0611486434936523\n",
      "[1, 99] loss: 1.0838672637939453, f1 score: 0.5909677319531109\n",
      "Train Epoch: 1 [ 3488/16586 (21.042471042471043%)]\tLoss: 1.024105191230774\n",
      "Train Epoch: 1 [ 3808/16586 (22.972972972972972%)]\tLoss: 1.1111904382705688\n",
      "[1, 119] loss: 1.0734946429729462, f1 score: 0.5802371484446049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [ 4128/16586 (24.903474903474905%)]\tLoss: 1.06731116771698\n",
      "Train Epoch: 1 [ 4448/16586 (26.833976833976834%)]\tLoss: 1.1324058771133423\n",
      "[1, 139] loss: 1.0898312032222748, f1 score: 0.558463519459284\n",
      "Train Epoch: 1 [ 4768/16586 (28.764478764478763%)]\tLoss: 1.0413399934768677\n",
      "Train Epoch: 1 [ 5088/16586 (30.694980694980696%)]\tLoss: 1.1142683029174805\n",
      "[1, 159] loss: 1.0903130173683167, f1 score: 0.5355530054426164\n",
      "Train Epoch: 1 [ 5408/16586 (32.625482625482626%)]\tLoss: 1.1556880474090576\n",
      "Train Epoch: 1 [ 5728/16586 (34.55598455598456%)]\tLoss: 0.9516394138336182\n",
      "[1, 179] loss: 1.0867957025766373, f1 score: 0.5761278656464974\n",
      "Train Epoch: 1 [ 6048/16586 (36.486486486486484%)]\tLoss: 1.1568149328231812\n",
      "Train Epoch: 1 [ 6368/16586 (38.41698841698842%)]\tLoss: 1.0243891477584839\n",
      "[1, 199] loss: 1.0711274474859238, f1 score: 0.6074356428776997\n",
      "Train Epoch: 1 [ 6688/16586 (40.34749034749035%)]\tLoss: 1.0079569816589355\n",
      "Train Epoch: 1 [ 7008/16586 (42.277992277992276%)]\tLoss: 1.0370231866836548\n",
      "[1, 219] loss: 1.0716430425643921, f1 score: 0.6399485239537998\n",
      "Train Epoch: 1 [ 7328/16586 (44.20849420849421%)]\tLoss: 1.0596492290496826\n",
      "Train Epoch: 1 [ 7648/16586 (46.13899613899614%)]\tLoss: 1.1318819522857666\n",
      "[1, 239] loss: 1.1151775896549225, f1 score: 0.5468659978560313\n",
      "Train Epoch: 1 [ 7968/16586 (48.06949806949807%)]\tLoss: 1.0661802291870117\n",
      "Train Epoch: 1 [ 8288/16586 (50.0%)]\tLoss: 1.101870059967041\n",
      "[1, 259] loss: 1.0826517790555954, f1 score: 0.5632272523194933\n",
      "Train Epoch: 1 [ 8608/16586 (51.93050193050193%)]\tLoss: 1.2188396453857422\n",
      "Train Epoch: 1 [ 8928/16586 (53.86100386100386%)]\tLoss: 1.1867635250091553\n",
      "[1, 279] loss: 1.1214730620384217, f1 score: 0.5239533830286853\n",
      "Train Epoch: 1 [ 9248/16586 (55.79150579150579%)]\tLoss: 1.1290453672409058\n",
      "Train Epoch: 1 [ 9568/16586 (57.722007722007724%)]\tLoss: 0.9995629787445068\n",
      "[1, 299] loss: 1.0934953689575195, f1 score: 0.5639197310710019\n",
      "Train Epoch: 1 [ 9888/16586 (59.65250965250965%)]\tLoss: 1.0819555521011353\n",
      "Train Epoch: 1 [ 10208/16586 (61.58301158301158%)]\tLoss: 1.2006769180297852\n",
      "[1, 319] loss: 1.0897910863161087, f1 score: 0.5216732876340558\n",
      "Train Epoch: 1 [ 10528/16586 (63.513513513513516%)]\tLoss: 1.092850923538208\n",
      "Train Epoch: 1 [ 10848/16586 (65.44401544401545%)]\tLoss: 1.0209320783615112\n",
      "[1, 339] loss: 1.103530126810074, f1 score: 0.557560936714504\n",
      "Train Epoch: 1 [ 11168/16586 (67.37451737451738%)]\tLoss: 1.0271939039230347\n",
      "Train Epoch: 1 [ 11488/16586 (69.3050193050193%)]\tLoss: 1.128261923789978\n",
      "[1, 359] loss: 1.0902183920145034, f1 score: 0.5527485329225051\n",
      "Train Epoch: 1 [ 11808/16586 (71.23552123552123%)]\tLoss: 1.0489590167999268\n",
      "Train Epoch: 1 [ 12128/16586 (73.16602316602317%)]\tLoss: 1.1097387075424194\n",
      "[1, 379] loss: 1.0688485145568847, f1 score: 0.5893075097925325\n",
      "Train Epoch: 1 [ 12448/16586 (75.0965250965251%)]\tLoss: 1.0303621292114258\n",
      "Train Epoch: 1 [ 12768/16586 (77.02702702702703%)]\tLoss: 1.079810619354248\n",
      "[1, 399] loss: 1.0809409379959107, f1 score: 0.5698646336852531\n",
      "Train Epoch: 1 [ 13088/16586 (78.95752895752896%)]\tLoss: 1.033350944519043\n",
      "Train Epoch: 1 [ 13408/16586 (80.88803088803088%)]\tLoss: 1.1682500839233398\n",
      "[1, 419] loss: 1.0833689033985139, f1 score: 0.5635843443799856\n",
      "Train Epoch: 1 [ 13728/16586 (82.81853281853282%)]\tLoss: 1.0042887926101685\n",
      "Train Epoch: 1 [ 14048/16586 (84.74903474903475%)]\tLoss: 0.9683837294578552\n",
      "[1, 439] loss: 1.0693320274353026, f1 score: 0.608485569521238\n",
      "Train Epoch: 1 [ 14368/16586 (86.67953667953668%)]\tLoss: 1.1266613006591797\n",
      "Train Epoch: 1 [ 14688/16586 (88.61003861003861%)]\tLoss: 1.0896990299224854\n",
      "[1, 459] loss: 1.081094205379486, f1 score: 0.5695555153544485\n",
      "Train Epoch: 1 [ 15008/16586 (90.54054054054055%)]\tLoss: 1.0388997793197632\n",
      "Train Epoch: 1 [ 15328/16586 (92.47104247104247%)]\tLoss: 0.9371643662452698\n",
      "[1, 479] loss: 1.0742423862218857, f1 score: 0.5618170925998525\n",
      "Train Epoch: 1 [ 15648/16586 (94.4015444015444%)]\tLoss: 1.0570663213729858\n",
      "Train Epoch: 1 [ 15968/16586 (96.33204633204633%)]\tLoss: 1.1585006713867188\n",
      "[1, 499] loss: 1.0782531470060348, f1 score: 0.5915774969250652\n",
      "Train Epoch: 1 [ 16288/16586 (98.26254826254826%)]\tLoss: 1.0366299152374268\n",
      "\n",
      "Epoch: 1, loss: 1.1262562274932861\n",
      "(epoch)time: 0:57:06.311683\n",
      "Model Saved\n",
      "epoch: 1, batch val: 0.5436507936507936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val)time: 0:05:34.159238\n",
      "Validation Score: 0.5390671584645487\n",
      "===============\n",
      "\n",
      "\n",
      "Train Epoch: 2 [ 288/16586 (1.7374517374517375%)]\tLoss: 1.1180622577667236\n",
      "Train Epoch: 2 [ 608/16586 (3.667953667953668%)]\tLoss: 1.0682106018066406\n",
      "[2, 19] loss: 1.057967695593834, f1 score: 0.6301587219661442\n",
      "Train Epoch: 2 [ 928/16586 (5.598455598455598%)]\tLoss: 1.0019720792770386\n",
      "Train Epoch: 2 [ 1248/16586 (7.528957528957529%)]\tLoss: 1.1235166788101196\n",
      "[2, 39] loss: 1.0738939493894577, f1 score: 0.5594519878189033\n",
      "Train Epoch: 2 [ 1568/16586 (9.45945945945946%)]\tLoss: 1.0742985010147095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [ 1888/16586 (11.38996138996139%)]\tLoss: 1.267951250076294\n",
      "[2, 59] loss: 1.050716796517372, f1 score: 0.5713387109233554\n",
      "Train Epoch: 2 [ 2208/16586 (13.32046332046332%)]\tLoss: 1.0978343486785889\n",
      "Train Epoch: 2 [ 2528/16586 (15.250965250965251%)]\tLoss: 1.1175251007080078\n",
      "[2, 79] loss: 1.080965381860733, f1 score: 0.5902437396650893\n",
      "Train Epoch: 2 [ 2848/16586 (17.18146718146718%)]\tLoss: 1.0313472747802734\n",
      "Train Epoch: 2 [ 3168/16586 (19.111969111969113%)]\tLoss: 1.1228665113449097\n",
      "[2, 99] loss: 1.0855274617671966, f1 score: 0.5321120632761198\n",
      "Train Epoch: 2 [ 3488/16586 (21.042471042471043%)]\tLoss: 1.0501922369003296\n",
      "Train Epoch: 2 [ 3808/16586 (22.972972972972972%)]\tLoss: 1.0164334774017334\n",
      "[2, 119] loss: 1.0743018180131911, f1 score: 0.5531043051643247\n",
      "Train Epoch: 2 [ 4128/16586 (24.903474903474905%)]\tLoss: 1.0303313732147217\n",
      "Train Epoch: 2 [ 4448/16586 (26.833976833976834%)]\tLoss: 0.9365984201431274\n",
      "[2, 139] loss: 1.0489572584629059, f1 score: 0.6345091300228352\n",
      "Train Epoch: 2 [ 4768/16586 (28.764478764478763%)]\tLoss: 1.0561360120773315\n",
      "Train Epoch: 2 [ 5088/16586 (30.694980694980696%)]\tLoss: 0.9718780517578125\n",
      "[2, 159] loss: 1.058313176035881, f1 score: 0.6177649728803074\n",
      "Train Epoch: 2 [ 5408/16586 (32.625482625482626%)]\tLoss: 1.068803310394287\n",
      "Train Epoch: 2 [ 5728/16586 (34.55598455598456%)]\tLoss: 1.1846094131469727\n",
      "[2, 179] loss: 1.0808343589305878, f1 score: 0.5549715025221531\n",
      "Train Epoch: 2 [ 6048/16586 (36.486486486486484%)]\tLoss: 1.0927859544754028\n",
      "Train Epoch: 2 [ 6368/16586 (38.41698841698842%)]\tLoss: 1.0605756044387817\n",
      "[2, 199] loss: 1.0717791587114334, f1 score: 0.5776733708751676\n",
      "Train Epoch: 2 [ 6688/16586 (40.34749034749035%)]\tLoss: 1.101422667503357\n",
      "Train Epoch: 2 [ 7008/16586 (42.277992277992276%)]\tLoss: 1.127458930015564\n",
      "[2, 219] loss: 1.0825308680534362, f1 score: 0.5198966616558242\n",
      "Train Epoch: 2 [ 7328/16586 (44.20849420849421%)]\tLoss: 1.1517078876495361\n",
      "Train Epoch: 2 [ 7648/16586 (46.13899613899614%)]\tLoss: 1.1143617630004883\n",
      "[2, 239] loss: 1.0855139434337615, f1 score: 0.5710239251483606\n",
      "Train Epoch: 2 [ 7968/16586 (48.06949806949807%)]\tLoss: 1.0031216144561768\n",
      "Train Epoch: 2 [ 8288/16586 (50.0%)]\tLoss: 1.215634822845459\n",
      "[2, 259] loss: 1.077729085087776, f1 score: 0.5841672050168962\n",
      "Train Epoch: 2 [ 8608/16586 (51.93050193050193%)]\tLoss: 1.1432443857192993\n",
      "Train Epoch: 2 [ 8928/16586 (53.86100386100386%)]\tLoss: 1.0398226976394653\n",
      "[2, 279] loss: 1.0631597965955735, f1 score: 0.5909415892857657\n",
      "Train Epoch: 2 [ 9248/16586 (55.79150579150579%)]\tLoss: 1.0691931247711182\n",
      "Train Epoch: 2 [ 9568/16586 (57.722007722007724%)]\tLoss: 1.0298199653625488\n",
      "[2, 299] loss: 1.060675522685051, f1 score: 0.6428824914508847\n",
      "Train Epoch: 2 [ 9888/16586 (59.65250965250965%)]\tLoss: 1.030361294746399\n",
      "Train Epoch: 2 [ 10208/16586 (61.58301158301158%)]\tLoss: 1.0805023908615112\n",
      "[2, 319] loss: 1.0785753756761551, f1 score: 0.5662821994757065\n",
      "Train Epoch: 2 [ 10528/16586 (63.513513513513516%)]\tLoss: 1.119706630706787\n",
      "Train Epoch: 2 [ 10848/16586 (65.44401544401545%)]\tLoss: 1.0925769805908203\n",
      "[2, 339] loss: 1.0727062582969666, f1 score: 0.5654255992810909\n",
      "Train Epoch: 2 [ 11168/16586 (67.37451737451738%)]\tLoss: 1.030296802520752\n",
      "Train Epoch: 2 [ 11488/16586 (69.3050193050193%)]\tLoss: 1.001906156539917\n",
      "[2, 359] loss: 1.064887171983719, f1 score: 0.5768456520595171\n",
      "Train Epoch: 2 [ 11808/16586 (71.23552123552123%)]\tLoss: 1.0256692171096802\n",
      "Train Epoch: 2 [ 12128/16586 (73.16602316602317%)]\tLoss: 1.1552066802978516\n",
      "[2, 379] loss: 1.0708397835493089, f1 score: 0.5694907298259073\n",
      "Train Epoch: 2 [ 12448/16586 (75.0965250965251%)]\tLoss: 1.0814170837402344\n",
      "Train Epoch: 2 [ 12768/16586 (77.02702702702703%)]\tLoss: 0.9696314930915833\n",
      "[2, 399] loss: 1.0718934088945389, f1 score: 0.5962371809271635\n",
      "Train Epoch: 2 [ 13088/16586 (78.95752895752896%)]\tLoss: 1.1547024250030518\n",
      "Train Epoch: 2 [ 13408/16586 (80.88803088803088%)]\tLoss: 0.9679346084594727\n",
      "[2, 419] loss: 1.0962965577840804, f1 score: 0.594757036006205\n",
      "Train Epoch: 2 [ 13728/16586 (82.81853281853282%)]\tLoss: 1.0301192998886108\n",
      "Train Epoch: 2 [ 14048/16586 (84.74903474903475%)]\tLoss: 1.1048433780670166\n",
      "[2, 439] loss: 1.080321553349495, f1 score: 0.5243562845602148\n",
      "Train Epoch: 2 [ 14368/16586 (86.67953667953668%)]\tLoss: 1.1117678880691528\n",
      "Train Epoch: 2 [ 14688/16586 (88.61003861003861%)]\tLoss: 1.1118954420089722\n",
      "[2, 459] loss: 1.0753071308135986, f1 score: 0.5626854833981714\n",
      "Train Epoch: 2 [ 15008/16586 (90.54054054054055%)]\tLoss: 1.0364071130752563\n",
      "Train Epoch: 2 [ 15328/16586 (92.47104247104247%)]\tLoss: 1.0925986766815186\n",
      "[2, 479] loss: 1.0650431513786316, f1 score: 0.5825076737926846\n",
      "Train Epoch: 2 [ 15648/16586 (94.4015444015444%)]\tLoss: 1.106142520904541\n",
      "Train Epoch: 2 [ 15968/16586 (96.33204633204633%)]\tLoss: 1.0307143926620483\n",
      "[2, 499] loss: 1.0728846877813338, f1 score: 0.5990297162264502\n",
      "Train Epoch: 2 [ 16288/16586 (98.26254826254826%)]\tLoss: 1.158539056777954\n",
      "\n",
      "Epoch: 2, loss: 1.1371574401855469\n",
      "(epoch)time: 0:56:01.172956\n",
      "Model Saved\n",
      "epoch: 2, batch val: 0.4500349406009783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val)time: 0:05:43.950020\n",
      "Validation Score: 0.5363153567318709\n",
      "===============\n",
      "\n",
      "\n",
      "Train Epoch: 3 [ 288/16586 (1.7374517374517375%)]\tLoss: 0.9893282055854797\n",
      "Train Epoch: 3 [ 608/16586 (3.667953667953668%)]\tLoss: 1.1367318630218506\n",
      "[3, 19] loss: 1.0615056127309799, f1 score: 0.5801000036460254\n",
      "Train Epoch: 3 [ 928/16586 (5.598455598455598%)]\tLoss: 1.068403720855713\n",
      "Train Epoch: 3 [ 1248/16586 (7.528957528957529%)]\tLoss: 1.006140112876892\n",
      "[3, 39] loss: 1.0354615598917007, f1 score: 0.6490052459432405\n",
      "Train Epoch: 3 [ 1568/16586 (9.45945945945946%)]\tLoss: 1.094694972038269\n",
      "Train Epoch: 3 [ 1888/16586 (11.38996138996139%)]\tLoss: 1.062666654586792\n",
      "[3, 59] loss: 1.0569303393363954, f1 score: 0.5913241814109292\n",
      "Train Epoch: 3 [ 2208/16586 (13.32046332046332%)]\tLoss: 1.1234194040298462\n",
      "Train Epoch: 3 [ 2528/16586 (15.250965250965251%)]\tLoss: 1.0298831462860107\n",
      "[3, 79] loss: 1.0796257197856902, f1 score: 0.5900770465600733\n",
      "Train Epoch: 3 [ 2848/16586 (17.18146718146718%)]\tLoss: 1.053832769393921\n",
      "Train Epoch: 3 [ 3168/16586 (19.111969111969113%)]\tLoss: 1.107731580734253\n",
      "[3, 99] loss: 1.0551283478736877, f1 score: 0.6062024856305712\n",
      "Train Epoch: 3 [ 3488/16586 (21.042471042471043%)]\tLoss: 1.0796085596084595\n",
      "Train Epoch: 3 [ 3808/16586 (22.972972972972972%)]\tLoss: 1.0857568979263306\n",
      "[3, 119] loss: 1.0680662661790847, f1 score: 0.5900814201885376\n",
      "Train Epoch: 3 [ 4128/16586 (24.903474903474905%)]\tLoss: 1.0305347442626953\n",
      "Train Epoch: 3 [ 4448/16586 (26.833976833976834%)]\tLoss: 1.0678796768188477\n",
      "[3, 139] loss: 1.0494366466999054, f1 score: 0.6253102107401661\n",
      "Train Epoch: 3 [ 4768/16586 (28.764478764478763%)]\tLoss: 1.1240941286087036\n",
      "Train Epoch: 3 [ 5088/16586 (30.694980694980696%)]\tLoss: 1.0938801765441895\n",
      "[3, 159] loss: 1.0701799780130385, f1 score: 0.5602371385487699\n",
      "Train Epoch: 3 [ 5408/16586 (32.625482625482626%)]\tLoss: 1.1406586170196533\n",
      "Train Epoch: 3 [ 5728/16586 (34.55598455598456%)]\tLoss: 1.055220365524292\n",
      "[3, 179] loss: 1.0767284661531449, f1 score: 0.5473805466213929\n",
      "Train Epoch: 3 [ 6048/16586 (36.486486486486484%)]\tLoss: 1.1558635234832764\n",
      "Train Epoch: 3 [ 6368/16586 (38.41698841698842%)]\tLoss: 1.034874439239502\n",
      "[3, 199] loss: 1.0600926250219345, f1 score: 0.6276703942182488\n",
      "Train Epoch: 3 [ 6688/16586 (40.34749034749035%)]\tLoss: 1.1383135318756104\n",
      "Train Epoch: 3 [ 7008/16586 (42.277992277992276%)]\tLoss: 0.9986827373504639\n",
      "[3, 219] loss: 1.0721841692924499, f1 score: 0.5849651246765705\n",
      "Train Epoch: 3 [ 7328/16586 (44.20849420849421%)]\tLoss: 1.1261780261993408\n",
      "Train Epoch: 3 [ 7648/16586 (46.13899613899614%)]\tLoss: 1.0949889421463013\n",
      "[3, 239] loss: 1.0601997256278992, f1 score: 0.5929422351186625\n",
      "Train Epoch: 3 [ 7968/16586 (48.06949806949807%)]\tLoss: 1.096449851989746\n",
      "Train Epoch: 3 [ 8288/16586 (50.0%)]\tLoss: 1.0925240516662598\n",
      "[3, 259] loss: 1.0749752402305603, f1 score: 0.5830373194654597\n",
      "Train Epoch: 3 [ 8608/16586 (51.93050193050193%)]\tLoss: 1.1667885780334473\n",
      "Train Epoch: 3 [ 8928/16586 (53.86100386100386%)]\tLoss: 1.0612585544586182\n",
      "[3, 279] loss: 1.083722048997879, f1 score: 0.570174477295365\n",
      "Train Epoch: 3 [ 9248/16586 (55.79150579150579%)]\tLoss: 1.0925885438919067\n",
      "Train Epoch: 3 [ 9568/16586 (57.722007722007724%)]\tLoss: 1.0657052993774414\n",
      "[3, 299] loss: 1.0490903198719024, f1 score: 0.6171250798956402\n",
      "Train Epoch: 3 [ 9888/16586 (59.65250965250965%)]\tLoss: 1.0220798254013062\n",
      "Train Epoch: 3 [ 10208/16586 (61.58301158301158%)]\tLoss: 1.1539874076843262\n",
      "[3, 319] loss: 1.0338154464960099, f1 score: 0.6255595951163482\n",
      "Train Epoch: 3 [ 10528/16586 (63.513513513513516%)]\tLoss: 1.0488358736038208\n",
      "Train Epoch: 3 [ 10848/16586 (65.44401544401545%)]\tLoss: 1.0953774452209473\n",
      "[3, 339] loss: 1.0735560655593872, f1 score: 0.5588885829762427\n",
      "Train Epoch: 3 [ 11168/16586 (67.37451737451738%)]\tLoss: 0.9412577748298645\n",
      "Train Epoch: 3 [ 11488/16586 (69.3050193050193%)]\tLoss: 1.0937929153442383\n",
      "[3, 359] loss: 1.0581609308719635, f1 score: 0.5580031711001967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [ 11808/16586 (71.23552123552123%)]\tLoss: 0.9667854309082031\n",
      "Train Epoch: 3 [ 12128/16586 (73.16602316602317%)]\tLoss: 0.9673558473587036\n",
      "[3, 379] loss: 1.0557889461517334, f1 score: 0.6236092671816454\n",
      "Train Epoch: 3 [ 12448/16586 (75.0965250965251%)]\tLoss: 1.0303927659988403\n",
      "Train Epoch: 3 [ 12768/16586 (77.02702702702703%)]\tLoss: 1.029209017753601\n",
      "[3, 399] loss: 1.0609510958194732, f1 score: 0.5483584075210388\n",
      "Train Epoch: 3 [ 13088/16586 (78.95752895752896%)]\tLoss: 1.061961054801941\n",
      "Train Epoch: 3 [ 13408/16586 (80.88803088803088%)]\tLoss: 1.0288991928100586\n",
      "[3, 419] loss: 1.0628407806158067, f1 score: 0.5876448349927703\n",
      "Train Epoch: 3 [ 13728/16586 (82.81853281853282%)]\tLoss: 1.0921491384506226\n",
      "Train Epoch: 3 [ 14048/16586 (84.74903474903475%)]\tLoss: 1.123348593711853\n",
      "[3, 439] loss: 1.063068261742592, f1 score: 0.6029652652652493\n",
      "Train Epoch: 3 [ 14368/16586 (86.67953667953668%)]\tLoss: 1.0088167190551758\n",
      "Train Epoch: 3 [ 14688/16586 (88.61003861003861%)]\tLoss: 1.0355371236801147\n",
      "[3, 459] loss: 1.057225489616394, f1 score: 0.562807027098627\n",
      "Train Epoch: 3 [ 15008/16586 (90.54054054054055%)]\tLoss: 1.0959789752960205\n",
      "Train Epoch: 3 [ 15328/16586 (92.47104247104247%)]\tLoss: 1.086866021156311\n",
      "[3, 479] loss: 1.060954859852791, f1 score: 0.6051907397078422\n",
      "Train Epoch: 3 [ 15648/16586 (94.4015444015444%)]\tLoss: 0.9987702369689941\n",
      "Train Epoch: 3 [ 15968/16586 (96.33204633204633%)]\tLoss: 1.1423313617706299\n",
      "[3, 499] loss: 1.0636140167713166, f1 score: 0.5791188448802979\n",
      "Train Epoch: 3 [ 16288/16586 (98.26254826254826%)]\tLoss: 1.1382946968078613\n",
      "\n",
      "Epoch: 3, loss: 1.1787792444229126\n",
      "(epoch)time: 0:56:44.361082\n",
      "Model Saved\n",
      "epoch: 3, batch val: 0.5120772946859903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val)time: 0:05:35.386633\n",
      "Validation Score: 0.5339131493658554\n",
      "===============\n",
      "\n",
      "\n",
      "Train Epoch: 4 [ 288/16586 (1.7374517374517375%)]\tLoss: 1.0693222284317017\n",
      "Train Epoch: 4 [ 608/16586 (3.667953667953668%)]\tLoss: 1.0517860651016235\n",
      "[4, 19] loss: 1.0493452727794648, f1 score: 0.5971817459512112\n",
      "Train Epoch: 4 [ 928/16586 (5.598455598455598%)]\tLoss: 1.1438467502593994\n",
      "Train Epoch: 4 [ 1248/16586 (7.528957528957529%)]\tLoss: 0.9788084626197815\n",
      "[4, 39] loss: 1.0538599461317062, f1 score: 0.5530541057985339\n",
      "Train Epoch: 4 [ 1568/16586 (9.45945945945946%)]\tLoss: 1.06111478805542\n",
      "Train Epoch: 4 [ 1888/16586 (11.38996138996139%)]\tLoss: 1.0646768808364868\n",
      "[4, 59] loss: 1.04953553378582, f1 score: 0.5999684152611388\n",
      "Train Epoch: 4 [ 2208/16586 (13.32046332046332%)]\tLoss: 1.03908109664917\n",
      "Train Epoch: 4 [ 2528/16586 (15.250965250965251%)]\tLoss: 1.095600962638855\n",
      "[4, 79] loss: 1.0736371845006942, f1 score: 0.5651593298583318\n",
      "Train Epoch: 4 [ 2848/16586 (17.18146718146718%)]\tLoss: 1.0010617971420288\n",
      "Train Epoch: 4 [ 3168/16586 (19.111969111969113%)]\tLoss: 1.0605436563491821\n",
      "[4, 99] loss: 1.0581959724426269, f1 score: 0.5898575119779588\n",
      "Train Epoch: 4 [ 3488/16586 (21.042471042471043%)]\tLoss: 1.052167296409607\n",
      "Train Epoch: 4 [ 3808/16586 (22.972972972972972%)]\tLoss: 1.0301477909088135\n",
      "[4, 119] loss: 1.0524908393621444, f1 score: 0.5697991546894984\n",
      "Train Epoch: 4 [ 4128/16586 (24.903474903474905%)]\tLoss: 0.9952511191368103\n",
      "Train Epoch: 4 [ 4448/16586 (26.833976833976834%)]\tLoss: 1.0304896831512451\n",
      "[4, 139] loss: 1.055201569199562, f1 score: 0.5841574829621818\n",
      "Train Epoch: 4 [ 4768/16586 (28.764478764478763%)]\tLoss: 1.0465658903121948\n",
      "Train Epoch: 4 [ 5088/16586 (30.694980694980696%)]\tLoss: 1.154874324798584\n",
      "[4, 159] loss: 1.052200499176979, f1 score: 0.6246438223888455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [ 5408/16586 (32.625482625482626%)]\tLoss: 1.0951530933380127\n",
      "Train Epoch: 4 [ 5728/16586 (34.55598455598456%)]\tLoss: 1.0318260192871094\n",
      "[4, 179] loss: 1.0547442764043808, f1 score: 0.5629687400676386\n",
      "Train Epoch: 4 [ 6048/16586 (36.486486486486484%)]\tLoss: 1.0547056198120117\n",
      "Train Epoch: 4 [ 6368/16586 (38.41698841698842%)]\tLoss: 1.1239038705825806\n",
      "[4, 199] loss: 1.0664322465658187, f1 score: 0.5584836419208716\n",
      "Train Epoch: 4 [ 6688/16586 (40.34749034749035%)]\tLoss: 1.0572574138641357\n",
      "Train Epoch: 4 [ 7008/16586 (42.277992277992276%)]\tLoss: 1.0321934223175049\n",
      "[4, 219] loss: 1.0351507723331452, f1 score: 0.5789414365310785\n",
      "Train Epoch: 4 [ 7328/16586 (44.20849420849421%)]\tLoss: 1.1515254974365234\n",
      "Train Epoch: 4 [ 7648/16586 (46.13899613899614%)]\tLoss: 1.024595856666565\n",
      "[4, 239] loss: 1.041838574409485, f1 score: 0.6098482126716325\n",
      "Train Epoch: 4 [ 7968/16586 (48.06949806949807%)]\tLoss: 1.0299476385116577\n",
      "Train Epoch: 4 [ 8288/16586 (50.0%)]\tLoss: 1.1374868154525757\n",
      "[4, 259] loss: 1.0699997782707213, f1 score: 0.581181257968523\n",
      "Train Epoch: 4 [ 8608/16586 (51.93050193050193%)]\tLoss: 1.1507412195205688\n",
      "Train Epoch: 4 [ 8928/16586 (53.86100386100386%)]\tLoss: 1.08389151096344\n",
      "[4, 279] loss: 1.0362895518541335, f1 score: 0.6573318409435125\n",
      "Train Epoch: 4 [ 9248/16586 (55.79150579150579%)]\tLoss: 1.1081557273864746\n",
      "Train Epoch: 4 [ 9568/16586 (57.722007722007724%)]\tLoss: 1.015647053718567\n",
      "[4, 299] loss: 1.0777177810668945, f1 score: 0.5748565083784145\n",
      "Train Epoch: 4 [ 9888/16586 (59.65250965250965%)]\tLoss: 0.9644997715950012\n",
      "Train Epoch: 4 [ 10208/16586 (61.58301158301158%)]\tLoss: 0.9959210157394409\n",
      "[4, 319] loss: 1.060845810174942, f1 score: 0.5776629367706612\n",
      "Train Epoch: 4 [ 10528/16586 (63.513513513513516%)]\tLoss: 1.018052101135254\n",
      "Train Epoch: 4 [ 10848/16586 (65.44401544401545%)]\tLoss: 1.075015902519226\n",
      "[4, 339] loss: 1.0522097319364547, f1 score: 0.5845802419503505\n",
      "Train Epoch: 4 [ 11168/16586 (67.37451737451738%)]\tLoss: 1.0924186706542969\n",
      "Train Epoch: 4 [ 11488/16586 (69.3050193050193%)]\tLoss: 1.0655601024627686\n",
      "[4, 359] loss: 1.0598797619342804, f1 score: 0.5952045525088551\n",
      "Train Epoch: 4 [ 11808/16586 (71.23552123552123%)]\tLoss: 1.1577850580215454\n",
      "Train Epoch: 4 [ 12128/16586 (73.16602316602317%)]\tLoss: 1.06643807888031\n",
      "[4, 379] loss: 1.0508271425962448, f1 score: 0.5895253244443366\n",
      "Train Epoch: 4 [ 12448/16586 (75.0965250965251%)]\tLoss: 1.1632473468780518\n",
      "Train Epoch: 4 [ 12768/16586 (77.02702702702703%)]\tLoss: 1.0944178104400635\n",
      "[4, 399] loss: 1.0743897438049317, f1 score: 0.5977001228522973\n",
      "Train Epoch: 4 [ 13088/16586 (78.95752895752896%)]\tLoss: 1.0634788274765015\n",
      "Train Epoch: 4 [ 13408/16586 (80.88803088803088%)]\tLoss: 1.0946667194366455\n",
      "[4, 419] loss: 1.0772370785474776, f1 score: 0.6011889182176757\n",
      "Train Epoch: 4 [ 13728/16586 (82.81853281853282%)]\tLoss: 0.9890516400337219\n",
      "Train Epoch: 4 [ 14048/16586 (84.74903474903475%)]\tLoss: 1.2499821186065674\n",
      "[4, 439] loss: 1.0625457108020782, f1 score: 0.5438629248985112\n",
      "Train Epoch: 4 [ 14368/16586 (86.67953667953668%)]\tLoss: 1.0879418849945068\n",
      "Train Epoch: 4 [ 14688/16586 (88.61003861003861%)]\tLoss: 1.0050413608551025\n",
      "[4, 459] loss: 1.0550627827644348, f1 score: 0.5962534481324661\n",
      "Train Epoch: 4 [ 15008/16586 (90.54054054054055%)]\tLoss: 1.0582177639007568\n",
      "Train Epoch: 4 [ 15328/16586 (92.47104247104247%)]\tLoss: 1.0049229860305786\n",
      "[4, 479] loss: 1.0540958493947983, f1 score: 0.5683461561250873\n",
      "Train Epoch: 4 [ 15648/16586 (94.4015444015444%)]\tLoss: 1.0864269733428955\n",
      "Train Epoch: 4 [ 15968/16586 (96.33204633204633%)]\tLoss: 1.056029200553894\n",
      "[4, 499] loss: 1.0682972252368927, f1 score: 0.5748478682263294\n",
      "Train Epoch: 4 [ 16288/16586 (98.26254826254826%)]\tLoss: 1.1125109195709229\n",
      "\n",
      "Epoch: 4, loss: 1.081007719039917\n",
      "(epoch)time: 0:57:26.346579\n",
      "Model Saved\n",
      "epoch: 4, batch val: 0.4797843665768194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(val)time: 0:05:29.485881\n",
      "Validation Score: 0.5275974077765792\n",
      "===============\n",
      "\n",
      "\n",
      "Epoch: 0, Score: 0.5135233857136235\n",
      "Epoch: 1, Score: 0.5390671584645487\n",
      "Epoch: 2, Score: 0.5363153567318709\n",
      "Epoch: 3, Score: 0.5339131493658554\n",
      "Epoch: 4, Score: 0.5275974077765792\n",
      "\n",
      "\n",
      "Model Saved, Finishing training\n",
      "TRAIN ended---duration:5:13:04.955022\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "os.makedirs('./log/', exist_ok=True)\n",
    "nth_trial = len(os.listdir('./log'))-1\n",
    "log_dir = (f'./log/trial{nth_trial}')\n",
    "os.makedirs(log_dir)\n",
    "\n",
    "DATASET_PATH = '/USER/kaggle/building/data/'\n",
    "TRAIN_RATIO = 0.9\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "# Set device (cpu or gpu)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "train()\n",
    "print(f'TRAIN ended---duration:{datetime.datetime.now() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-12 06:50:15.605501\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# log_dir = './log/trial1'\n",
    "# weight = 'epoch_2.pth'\n",
    "\n",
    "# test()\n",
    "# print(f'TEST ended---duration:{datetime.datetime.now() - start}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
